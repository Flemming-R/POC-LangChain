{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=aywZrzNaKjs&ab_channel=Rabbitmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     \tID          \tSIZE  \tMODIFIED     \n",
      "deepseek-r1:8b           \t28f8fd6cdc67\t4.9 GB\t22 hours ago\t\n",
      "llama3.2:1b-instruct-q4_0\t53f2745c8077\t770 MB\t3 months ago\t\n",
      "llama3.2:1b              \tbaf6a787fdff\t1.3 GB\t3 months ago\t\n",
      "llama3.1:8b              \t42182419e950\t4.7 GB\t4 months ago\t\n",
      "mistral:instruct         \tf974a74358d6\t4.1 GB\t4 months ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import langchain_ollama\n",
    "import langchain_core\n",
    "import langchain_community\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core import messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"deepseek-r1:8b\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(\n",
    "    top_k_results=3,\n",
    "    lang=\"en\",\n",
    "    load_all_available_pages=True,\n",
    "    load_all_available_meta = True,\n",
    "    doc_content_chars_max=4000\n",
    ")\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Use the following context to answer the question:\n",
    "    \n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "If the information is not in the context, say \"I don't have enough information from Wikipedia to answer this.\"\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_from_wikipedia(question):\n",
    "    # Wikipedia durchsuchen\n",
    "    context = wikipedia_tool.run(question)\n",
    "    \n",
    "    # Antwort ausgeben\n",
    "    chain = (\n",
    "        {\"context\": lambda x: context, \"question\": RunnablePassthrough()}\n",
    "        | prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "def retrieve_from_wikipedia_with_context(question):\n",
    "    # Konfiguriere API-Wrapper mit mehr Details\n",
    "    api_wrapper = WikipediaAPIWrapper(\n",
    "                                        top_k_results=3,\n",
    "                                        lang=\"en\",\n",
    "                                        load_all_available_pages=True,\n",
    "                                        load_all_available_meta = True,\n",
    "                                        doc_content_chars_max=4000\n",
    ")\n",
    "    wikipedia_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "    \n",
    "    # Wikipedia durchsuchen\n",
    "    context = wikipedia_tool.run(question)\n",
    "    \n",
    "    # Ausführliche Kontextausgabe\n",
    "    print(\"===== WIKIPEDIA SEARCH DETAILS =====\")\n",
    "    print(f\"Search Query: {question}\")\n",
    "    print(f\"Retrieved Context Length: {len(context)} characters\")\n",
    "    print(\"Context Preview:\")\n",
    "    print(context[:500] + \"...\" if len(context) > 500 else context)\n",
    "    print(\"====================================\")\n",
    "    \n",
    "    # Antwort generieren\n",
    "    chain = (\n",
    "        {\"context\": lambda x: context, \"question\": RunnablePassthrough()}\n",
    "        | prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return chain.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== WIKIPEDIA SEARCH DETAILS =====\n",
      "Search Query: What is DeepSeek?\n",
      "Retrieved Context Length: 4000 characters\n",
      "Context Preview:\n",
      "Page: DeepSeek\n",
      "Summary: DeepSeek (stylized as deepseek, Chinese: 深度求索; pinyin: Shēndù Qiúsuǒ) is a Chinese artificial intelligence company that develops open-source large language models (LLMs). Based in Hangzhou, Zhejiang, it is owned and funded by Chinese hedge fund High-Flyer, whose co-founder, Liang Wenfeng, established the company in 2023 and serves as its CEO. \n",
      "The DeepSeek-R1 model provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4o and o1. I...\n",
      "====================================\n",
      "<think>\n",
      "Okay, so I need to figure out what DeepSeek is based on the given context. Let me start by reading through the context carefully.\n",
      "\n",
      "First, there's a summary for Page: DeepSeek. It mentions that DeepSeek is a Chinese AI company that develops open-source large language models (LLMs). They're based in Hangzhou and owned by High-Flyer Capital, which was founded by Liang Wenfeng, who is their CEO. The model they use, DeepSeek-R1, provides responses comparable to other LLMs like GPT-4 but at a much lower cost—$6 million compared to OpenAI's $100 million in 2023. They also require less computing power, which is a tenth of similar models.\n",
      "\n",
      "The context also notes that DeepSeek was established during U.S. sanctions on China for Nvidia chips, which were meant to restrict China's AI development. In January 2025, they released their first free chatbot app based on R1, and it became the most downloaded free app in the U.S. App Store within a week, causing Nvidia's stock to drop by 18%. This success is described as \"upending AI\" and starting a global race in AI.\n",
      "\n",
      "Additionally, DeepSeek makes their generative AI algorithms, models, and training details open-source, allowing others to use, modify, and design with their code. They recruit top AI researchers and also hire from outside computer science to diversify their models' knowledge.\n",
      "\n",
      "Now, considering the question: What is DeepSeek? I need to summarize this information clearly.\n",
      "\n",
      "I should mention that it's a Chinese AI company founded in 2023 by Liang Wenfeng. They focus on open-source LLMs with models like R1, which are cost-effective and require less computational power. Their success against bigger competitors like OpenAI is significant, especially given the sanctions they faced. They've also released a chatbot app that performed well, impacting Nvidia's stock. Plus, their commitment to open-source and diverse hiring practices sets them apart.\n",
      "\n",
      "I should structure this in a clear, concise manner without using markdown, just plain text as per the instructions.\n",
      "</think>\n",
      "\n",
      "DeepSeek is a Chinese artificial intelligence company established in 2023 by High-Flyer Capital, led by CEO Liang Wenfeng. Specializing in open-source large language models (LLMs), DeepSeek's R1 model offers comparable performance to contemporaries like GPT-4 at a fraction of the cost and computational requirements. Despite facing U.S. sanctions on access to Nvidia chips, DeepSeek achieved significant success with its free chatbot app, becoming the most downloaded in the U.S. App Store within a week and causing a notable drop in Nvidia's stock price. The company emphasizes open-source practices, recruiting top AI researchers, and diversifying their models by hiring from various fields, positioning them as a leader in the global AI race.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "result = retrieve_from_wikipedia_with_context(\"What is DeepSeek?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-lernen-GE3QnVly-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
