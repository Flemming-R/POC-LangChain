{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grundlage:\n",
    "* https://js.langchain.com/v0.1/docs/modules/chains/popular/sqlite/\n",
    "* https://js.langchain.com/v0.1/docs/integrations/toolkits/sql/\n",
    "\n",
    "* https://python.langchain.com/docs/tutorials/sql_qa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import langchain\n",
    "from langchain_community.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = r\"./POC-LangChain/chinook-database-master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'AntÃ´nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "Sequence of steps that does the following:\n",
    "* converts the question into a SQL query;\n",
    "* executes the query;\n",
    "* uses the result to answer the original question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flemm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-lernen-GE3QnVly-py3.11\\Lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "assert len(query_prompt_template.messages) == 1\n",
    "query_prompt_template.messages[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     \tID          \tSIZE  \tMODIFIED     \n",
      "qwen2.5-coder:7b         \t2b0496514337\t4.7 GB\t9 hours ago \t\n",
      "deepseek-r1:8b           \t28f8fd6cdc67\t4.9 GB\t2 days ago  \t\n",
      "llama3.2:1b-instruct-q4_0\t53f2745c8077\t770 MB\t3 months ago\t\n",
      "llama3.2:1b              \tbaf6a787fdff\t1.3 GB\t3 months ago\t\n",
      "llama3.1:8b              \t42182419e950\t4.7 GB\t4 months ago\t\n",
      "mistral:instruct         \tf974a74358d6\t4.1 GB\t4 months ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "class FlemmingsChatOllama(ChatOllama):\n",
    "    def with_structured_output(self, schema, *, include_raw=False, **kwargs):\n",
    "        # Call bind_tools without the format parameter\n",
    "        llm = self.bind_tools(tools=[schema])  # omit format=\"json\"\n",
    "        from langchain_core.output_parsers.pydantic import PydanticOutputParser\n",
    "        from langchain_core.output_parsers.json import JsonOutputParser\n",
    "        is_pydantic_schema = isinstance(schema, type)  # simplified check\n",
    "        output_parser = (PydanticOutputParser(pydantic_object=schema)\n",
    "                         if is_pydantic_schema else JsonOutputParser())\n",
    "        # Compose the output parser\n",
    "        from langchain_core.runnables import RunnableLambda\n",
    "        parser_chain = RunnableLambda(lambda x: x) | output_parser\n",
    "        # If include_raw is requested, add a passthrough (optional)\n",
    "        if include_raw:\n",
    "            from langchain_core.runnables.passthrough import RunnablePassthrough\n",
    "            parser_assign = RunnablePassthrough.assign(parsed=lambda x: parser_chain.invoke(x),\n",
    "                                                        parsing_error=lambda _: None)\n",
    "            return llm | parser_assign\n",
    "        else:\n",
    "            return llm | parser_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def clean_response(raw_text: str) -> str:\n",
    "    # Remove any header tokens like <|start_header_id|>assistant<|end_header_id|>\n",
    "    cleaned = re.sub(r\"<\\|start_header_id\\|>.*?<\\|end_header_id\\|>\\s*\", \"\", raw_text, flags=re.DOTALL)\n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlemmingsChatOllama(\n",
    "    model=\n",
    "        'llama3.2:1b',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\n",
    "        'llama3.2:1b',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_2(state: dict):\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "    # raw response\n",
    "    raw_response = model.invoke(prompt).content\n",
    "    # Clean header tokens\n",
    "    cleaned = clean_response(raw_response)\n",
    "    # wrap the plain text SQL query in a JSON object\n",
    "    return {\"query\": cleaned}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query(state: dict):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "    llm = model\n",
    "\n",
    "    structured_llm = llm.with_structured_output(QueryOutput, method=\"json_schema\")\n",
    "\n",
    "    result = structured_llm.invoke(prompt)\n",
    "\n",
    "    if not isinstance(result, dict):\n",
    "\n",
    "        cleaned = clean_response(result)\n",
    "        parsed = json.loads(cleaned)\n",
    "        result = parsed\n",
    "    return {\"query\": result[\"query\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'llm' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mwrite_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGive me the top 10 customers based on money spent.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m, in \u001b[0;36mwrite_query\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate SQL query to fetch information.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m query_prompt_template\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialect\u001b[39m\u001b[38;5;124m\"\u001b[39m: db\u001b[38;5;241m.\u001b[39mdialect,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: db\u001b[38;5;241m.\u001b[39mget_table_info(),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m })\n\u001b[1;32m----> 9\u001b[0m llm\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#llm = model\u001b[39;00m\n\u001b[0;32m     12\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(QueryOutput, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_schema\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'llm' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "write_query({\"question\": \n",
    "             \"Give me the top 10 customers based on money spent.\"\n",
    "             })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-lernen-GE3QnVly-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
