{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grundlage:\n",
    "* https://js.langchain.com/v0.1/docs/modules/chains/popular/sqlite/\n",
    "* https://js.langchain.com/v0.1/docs/integrations/toolkits/sql/\n",
    "\n",
    "* https://python.langchain.com/docs/tutorials/sql_qa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import langchain\n",
    "from langchain_community.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = r\"./POC-LangChain/chinook-database-master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'AntÃ´nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "Sequence of steps that does the following:\n",
    "* converts the question into a SQL query;\n",
    "* executes the query;\n",
    "* uses the result to answer the original question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flemm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-lernen-GE3QnVly-py3.11\\Lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "assert len(query_prompt_template.messages) == 1\n",
    "query_prompt_template.messages[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     \tID          \tSIZE  \tMODIFIED     \n",
      "qwen2.5-coder:7b         \t2b0496514337\t4.7 GB\t3 hours ago \t\n",
      "deepseek-r1:8b           \t28f8fd6cdc67\t4.9 GB\t2 days ago  \t\n",
      "llama3.2:1b-instruct-q4_0\t53f2745c8077\t770 MB\t3 months ago\t\n",
      "llama3.2:1b              \tbaf6a787fdff\t1.3 GB\t3 months ago\t\n",
      "llama3.1:8b              \t42182419e950\t4.7 GB\t4 months ago\t\n",
      "mistral:instruct         \tf974a74358d6\t4.1 GB\t4 months ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "class MyChatOllama(ChatOllama):\n",
    "    def with_structured_output(self, schema, *, include_raw=False, **kwargs):\n",
    "        # Call bind_tools without the format parameter\n",
    "        llm = self.bind_tools(tools=[schema])  # omit format=\"json\"\n",
    "        from langchain_core.output_parsers.pydantic import PydanticOutputParser\n",
    "        from langchain_core.output_parsers.json import JsonOutputParser\n",
    "        is_pydantic_schema = isinstance(schema, type)  # simplified check\n",
    "        output_parser = (PydanticOutputParser(pydantic_object=schema)\n",
    "                         if is_pydantic_schema else JsonOutputParser())\n",
    "        # Compose the output parser\n",
    "        from langchain_core.runnables import RunnableLambda\n",
    "        parser_chain = RunnableLambda(lambda x: x) | output_parser\n",
    "        # If include_raw is requested, add a passthrough (optional)\n",
    "        if include_raw:\n",
    "            from langchain_core.runnables.passthrough import RunnablePassthrough\n",
    "            parser_assign = RunnablePassthrough.assign(parsed=lambda x: parser_chain.invoke(x),\n",
    "                                                        parsing_error=lambda _: None)\n",
    "            return llm | parser_assign\n",
    "        else:\n",
    "            return llm | parser_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def clean_response(raw_text: str) -> str:\n",
    "    # Remove any header tokens like <|start_header_id|>assistant<|end_header_id|>\n",
    "    cleaned = re.sub(r\"<\\|start_header_id\\|>.*?<\\|end_header_id\\|>\\s*\", \"\", raw_text, flags=re.DOTALL)\n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyChatOllama(\n",
    "    model=\n",
    "        'llama3.2:1b',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query(state: dict):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "    llm = model\n",
    "    # Try json_schema method (you can also experiment with function_calling)\n",
    "    structured_llm = llm.with_structured_output(QueryOutput, method=\"json_schema\")\n",
    "    # Invoke the chain\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    # If result is not valid JSON, attempt to clean it\n",
    "    if not isinstance(result, dict):\n",
    "        # Assuming result is a string containing extra tokens, clean it first.\n",
    "        cleaned = clean_response(result)\n",
    "        parsed = json.loads(cleaned)\n",
    "        result = parsed\n",
    "    return {\"query\": result[\"query\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query(state: dict):\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "    # Get the raw response\n",
    "    raw_response = model.invoke(prompt).content\n",
    "    # Clean header tokens\n",
    "    cleaned = clean_response(raw_response)\n",
    "    # Now wrap the plain text SQL query in a JSON object\n",
    "    # You could also add validation here if needed.\n",
    "    return {\"query\": cleaned}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT T1.GenreId FROM Genre AS T1 INNER JOIN Genre AS T2 ON T1.GenreId = T2.GenreId ORDER BY COUNT(T1.Name) DESC LIMIT 3'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query({\"question\": \"What are the three most popular genres?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-lernen-GE3QnVly-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
