{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grundlage:\n",
    "* https://js.langchain.com/v0.1/docs/modules/chains/popular/sqlite/\n",
    "* https://js.langchain.com/v0.1/docs/integrations/toolkits/sql/\n",
    "\n",
    "* https://python.langchain.com/docs/tutorials/sql_qa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import langchain\n",
    "from langchain_community.utilities import SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = r\"./POC-LangChain/chinook-database-master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Album',\n",
       " 'Artist',\n",
       " 'Customer',\n",
       " 'Employee',\n",
       " 'Genre',\n",
       " 'Invoice',\n",
       " 'InvoiceLine',\n",
       " 'MediaType',\n",
       " 'Playlist',\n",
       " 'PlaylistTrack',\n",
       " 'Track']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(db.dialect)\n",
    "db.get_usable_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt Template** - Definieren, wie die Frage in eine SQL-Anweisung übersetzt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_template = \"\"\"\n",
    "Du bist ein SQL-Experte, der ausschließlich lesende (SELECT-)Abfragen schreibt.\n",
    "Deine Aufgabe ist es, aus einer natürlichen Spracheingabe eine korrekte SQL-Abfrage zu erstellen,\n",
    "die exakt auf das folgende Datenbankschema abgestimmt ist. Beachte bitte:\n",
    "  - Verwende nur die Tabellen und Spalten, die im Schema aufgeführt sind.\n",
    "  - Schreibe ausschließlich SELECT-Abfragen, keine INSERT-, UPDATE- oder DELETE-Anweisungen.\n",
    "  - Wenn du die Antwort nicht sicher ableiten kannst, gib eine höfliche Meldung zurück, dass die Frage unklar ist.\n",
    "\n",
    "Bitte verwende exakt das folgende Format:\n",
    "\n",
    "Frage: <die ursprüngliche Frage>\n",
    "SQL-Abfrage: <die generierte SQL-Abfrage>\n",
    "SQL-Ergebnis: <das Ergebnis der SQL-Abfrage>\n",
    "Antwort: <eine klare, kurze und präzise Antwort auf die ursprüngliche Frage>\n",
    "\n",
    "Nutze das unten stehende Datenbankschema:\n",
    "{dbschema}\n",
    "\n",
    "Frage: {question}\n",
    "SQL-Abfrage:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrate the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import List, Optional, Mapping, Any\n",
    "from langchain.llms.base import LLM\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    model: str\n",
    "    base_url: str = \"http://localhost:11434\"\n",
    "    token: Optional[str] = None\n",
    "    temperature: float = 0.7\n",
    "    max_tokens: int = 256\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs: Any) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"options\": {\n",
    "                \"temperature\": self.temperature,\n",
    "                \"num_predict\": self.max_tokens,\n",
    "            },\n",
    "            \"token\": self.token or \"\"\n",
    "        }\n",
    "        url = f\"{self.base_url}/api/generate\"\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        # Adjust this key depending on your Ollama API response format\n",
    "        return data.get(\"response\", \"\").strip()\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"model\": self.model, \"base_url\": self.base_url}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     \tID          \tSIZE  \tMODIFIED     \n",
      "qwen2.5-coder:7b         \t2b0496514337\t4.7 GB\t31 hours ago\t\n",
      "deepseek-r1:8b           \t28f8fd6cdc67\t4.9 GB\t3 days ago  \t\n",
      "llama3.2:1b-instruct-q4_0\t53f2745c8077\t770 MB\t3 months ago\t\n",
      "llama3.2:1b              \tbaf6a787fdff\t1.3 GB\t3 months ago\t\n",
      "llama3.1:8b              \t42182419e950\t4.7 GB\t4 months ago\t\n",
      "mistral:instruct         \tf974a74358d6\t4.1 GB\t4 months ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query:\n",
      "Um auf deine Frage zu antworten:\n",
      "\n",
      "\"Zeige alle Tracks aus dem Album Jazz\"\n",
      "\n",
      "Die korrekte SQL-Abfrage wäre:\n",
      "\n",
      "```sql\n",
      "SELECT T1.Name \n",
      "FROM Track AS T1 \n",
      "INNER JOIN Album AS T2 ON T1.AlbumID = T2.AlbumID \n",
      "WHERE T2.Title = 'Jazz';\n",
      "```\n",
      "\n",
      "Dabei wird das Ergebnis basierend auf der Auflistung aller Tracks (T1) mit dem Album \"Jazz\" (T2) ausgewählt.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "def generate_sql(prompt, model=\"llama3.1:8B\", token=\"your_api_token_here\", temperature=0.7, max_tokens=256, base_url=\"http://localhost:11434\"):\n",
    "    # Prepare the payload with streaming disabled\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"options\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"num_predict\": max_tokens\n",
    "        },\n",
    "        \"token\": token,\n",
    "        \"stream\": False  # Disable streaming to get a complete response\n",
    "    }\n",
    "    url = f\"{base_url}/api/generate\"\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the complete JSON response\n",
    "    data = response.json()\n",
    "    # Assuming the API returns the generated SQL under the \"response\" key:\n",
    "    return data.get(\"response\", \"\").strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the SQL prompt template using LangChain's PromptTemplate\n",
    "    sql_template = \"\"\"\n",
    "Du bist ein SQL-Experte, der ausschließlich SELECT-Abfragen generiert.\n",
    "Deine Aufgabe ist es, aus der natürlichen Spracheingabe eine korrekte SQL-Abfrage zu erstellen,\n",
    "die exakt auf das folgende Datenbankschema abgestimmt ist.\n",
    "Verwende nur die aufgeführten Tabellen und Spalten.\n",
    "Falls die Frage unklar ist, gib eine höfliche Meldung zurück.\n",
    "\n",
    "Datenbankschema:\n",
    "{dbschema}\n",
    "\n",
    "Frage: {question}\n",
    "SQL-Abfrage:\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"dbschema\", \"question\"],\n",
    "        template=sql_template\n",
    "    )\n",
    "    \n",
    "    # Example database schema and question\n",
    "    dbschema = \"Album(AlbumID, Title, ArtistID); Artist(ArtistID, Name); Track(TrackID, Name, AlbumID)\"\n",
    "    question = \"Zeige alle Tracks aus dem Album Jazz\"\n",
    "    \n",
    "    # Generate the final prompt using the template\n",
    "    prompt = prompt_template.format(dbschema=dbschema, question=question)\n",
    "    sql_query = generate_sql(prompt)\n",
    "    print(\"Generated SQL Query:\")\n",
    "    print(sql_query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-lernen-GE3QnVly-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
